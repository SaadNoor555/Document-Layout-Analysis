{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### This notebook was inspired from [here](https://www.kaggle.com/code/ammarnassanalhajali/layout-parser-model-training)","metadata":{"_uuid":"6b29edbd-8c64-44db-a23f-86362876a0f3","_cell_guid":"3495a8fc-e127-475a-bdcb-fb1e81f6f0e2","trusted":true}},{"cell_type":"markdown","source":"# Detectron2\n\n[Detectron2](https://detectron2.readthedocs.io/en/latest/index.html) is a popular open-source software library developed by Facebook AI Research (FAIR) for building computer vision models. It serves as a powerful framework for object detection, instance segmentation, and keypoint detection tasks. Detectron2 is built on top of PyTorch, geared towards a more convenient way to build modular, flexible pipelines for specific Computer Vision Tasks such as object detection, instance segmentation. \n\nDetectron2 has a collection of trained models for these tasks in their [model zoo](https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md). We can also use detectron2 to train pre-implemented state-of-the-art models from scratch for new datasets, as we do in this notebook. \n\nRead the [documentation](https://detectron2.readthedocs.io/en/latest/index.html).","metadata":{"_uuid":"35f8fa00-aaf9-49d4-99c9-eef323a5bcaa","_cell_guid":"9943a280-0d42-4e49-a1c6-4370bd642b9e","trusted":true}},{"cell_type":"markdown","source":"# 1 Install detectron2","metadata":{"_uuid":"9b02c72d-3d68-409f-a8b9-6962902fbf7d","_cell_guid":"6c93d80d-d7e7-4a94-9323-a1731dfd6089","trusted":true}},{"cell_type":"markdown","source":"## 1.1 Recommended Way (is not working on kaggle)","metadata":{"_uuid":"542c1737-d365-4e12-897a-54a913e86756","_cell_guid":"804e7670-9296-404a-9300-4f71b800df68","trusted":true}},{"cell_type":"code","source":"# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"b4a6002d-2e26-40e6-a4d8-a4071d065a59","_cell_guid":"3c6728ac-6fd6-483e-aae2-74246d89f2c9","collapsed":false,"_kg_hide-input":false,"_kg_hide-output":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"","metadata":{"_uuid":"cf5d6576-1ed0-4c55-b5ed-d24a9ac2bdef","_cell_guid":"2a3e1840-b15c-49ba-98d7-b186d5e7c04c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-05T04:41:33.129712Z","iopub.execute_input":"2023-08-05T04:41:33.130151Z","iopub.status.idle":"2023-08-05T04:41:33.135747Z","shell.execute_reply.started":"2023-08-05T04:41:33.130119Z","shell.execute_reply":"2023-08-05T04:41:33.134349Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Fast Way\nIgnore the warnings.","metadata":{"_uuid":"676aae46-30ee-4ed0-b1e8-def5aab8c420","_cell_guid":"0c31f77b-90c2-425f-bf7a-7a8b37ed023a","trusted":true}},{"cell_type":"code","source":"%%capture\nimport sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))","metadata":{"_uuid":"90c1d2f7-a38f-440b-9bd2-60502fdfa668","_cell_guid":"6e319fef-6748-4cd2-945c-abbbf0d05048","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-05T04:41:33.676497Z","iopub.execute_input":"2023-08-05T04:41:33.677268Z","iopub.status.idle":"2023-08-05T04:42:33.249692Z","shell.execute_reply.started":"2023-08-05T04:41:33.677230Z","shell.execute_reply":"2023-08-05T04:42:33.248199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 2 Notebook Config","metadata":{"_uuid":"cd3af0ca-eafa-4e37-b6ee-d374c79499e2","_cell_guid":"ac18bd10-5e91-41fa-b7da-a051c9a718da","trusted":true}},{"cell_type":"code","source":"\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n\n\nfrom datetime import datetime\n\n# if False, model is set to `PRETRAINED_PATH` model\nis_train = True\n\n# if True, evaluate on validation dataset\nis_evaluate = True\n\n# if True, run inference on test dataset\nis_inference = True\n\n# if True and `is_train` == True, `PRETRAINED_PATH` model is trained further\nis_resume_training = False\n\n# Perform augmentation\nis_augment = False\n\nSEED = 42\nimport random\nimport os\nimport numpy as np\nimport torch\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n\n\"\"\"## 2.2 Paths\"\"\"\n\nfrom pathlib import Path\n\nTRAIN_IMG_DIR = Path(\"/kaggle/input/dlsprint2/badlad/images/train\")\n\nTRAIN_COCO_PATH = Path(\"/kaggle/input/dlsprint2/badlad/labels/coco_format/train/badlad-train-coco.json\")\n\nTEST_IMG_DIR = Path(\"/kaggle/input/dlsprint2/badlad/images/test\")\n\nTEST_METADATA_PATH = Path(\"/kaggle/input/dlsprint2/badlad/badlad-test-metadata.json\")\n\n# Training output directory\nOUTPUT_DIR = Path(\"./output\")\nOUTPUT_MODEL = OUTPUT_DIR/\"model_final.pth\"\n\n# Path to your pretrained model weights\nPRETRAINED_PATH = Path(\"\")\n\n\"\"\"## 2.3 imports\"\"\"\n\n# detectron2\nfrom detectron2.utils.memory import retry_if_cuda_oom\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.modeling import build_model\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nimport detectron2.data.transforms as T\nfrom detectron2.data import detection_utils as utils\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader, DatasetMapper\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2 import model_zoo\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm  # progress bar\nimport matplotlib.pyplot as plt\nimport json\nimport cv2\nimport copy\nfrom typing import Optional\n\nfrom IPython.display import FileLink\n\n# torch\nimport torch\nimport os\n\nimport gc\n\nimport warnings\n# Ignore \"future\" warnings and Data-Frame-Slicing warnings.\nwarnings.filterwarnings('ignore')\n\nsetup_logger()\n\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n\n\"\"\"# 3 COCO Annotations Data\n\n## 3.1 Load\n\"\"\"\n\nwith TRAIN_COCO_PATH.open() as f:\n    train_dict = json.load(f)\n\nwith TEST_METADATA_PATH.open() as f:\n    test_dict = json.load(f)\n\nprint(\"#### LABELS AND METADATA LOADED ####\")\n\n\"\"\"## 3.2 Observe\"\"\"\n\ndef organize_coco_data(data_dict: dict):\n    thing_classes: list[str] = []\n\n    # Map Category Names to IDs\n    for cat in data_dict['categories']:\n        thing_classes.append(cat['name'])\n\n    print(thing_classes)\n\n    # thing_classes = ['paragraph', 'text_box', 'image', 'table']\n    # Images\n    images_metadata: list[dict] = data_dict['images']\n\n    # Convert COCO annotations to detectron2 annotations format\n    data_annotations = []\n    for ann in data_dict['annotations']:\n        # coco format -> detectron2 format\n        annot_obj = {\n            # Annotation ID\n            \"id\": ann['id'],\n\n            # Segmentation Polygon (x, y) coords\n            \"gt_masks\": ann['segmentation'],\n\n            # Image ID for this annotation (Which image does this annotation belong to?)\n            \"image_id\": ann['image_id'],\n\n            # Category Label (0: paragraph, 1: text box, 2: image, 3: table)\n            \"category_id\": ann['category_id'],\n\n            \"x_min\": ann['bbox'][0],  # left\n            \"y_min\": ann['bbox'][1],  # top\n            \"x_max\": ann['bbox'][0] + ann['bbox'][2],  # left+width\n            \"y_max\": ann['bbox'][1] + ann['bbox'][3]  # top+height\n        }\n        data_annotations.append(annot_obj)\n\n    return thing_classes, images_metadata, data_annotations\n\nthing_classes, images_metadata_train, train_data_annotations = organize_coco_data(\n    train_dict\n)\n\nthing_classes_test, images_metadata_test, _ = organize_coco_data(\n    test_dict\n)\n\ntrain_metadata = pd.DataFrame(images_metadata_train)\ntrain_metadata = train_metadata[['id', 'file_name', 'width', 'height']]\ntrain_metadata = train_metadata.rename(columns={\"id\": \"image_id\"})\nprint(\"train_metadata size=\", len(train_metadata))\ntrain_metadata.head(5)\n\ntrain_annot_df = pd.DataFrame(train_data_annotations)\nprint(\"train_annot_df size=\", len(train_annot_df))\ntrain_annot_df.head(5)\n\n\"\"\"Here `gt_masks` are the sequence of `(x, y)` coordinates of vertices of the polygon surrounding the target object.\"\"\"\n\n# test_metadata = pd.DataFrame(images_metadata_test)\n# test_metadata = test_metadata[['id', 'file_name', 'width', 'height']]\n# test_metadata = test_metadata.rename(columns={\"id\": \"image_id\"})\n# print(\"test_metadata size=\", len(test_metadata))\n# test_metadata.head(5)\n\n\"\"\"These are the categories we are going to detect.\"\"\"\n\nprint(thing_classes)\n\nDATA_REGISTER_TRAINING = \"badlad_train\"\nDATA_REGISTER_VALID    = \"badlad_valid\"\nDATA_REGISTER_TEST     = \"badlad_test\"\n\ntrain_df_with_annotations = train_metadata.merge(train_annot_df, on='image_id')\ntrain_df_with_annotations.head()\n\n# Group annotations by image_id and aggregate into a list\ntrain_df_with_annotations_grouped = train_df_with_annotations.groupby('image_id').agg(lambda x: x.tolist()).reset_index()\ntrain_df_with_annotations_grouped.head()\n\ntorch.cuda.empty_cache()\ngc.collect()\n\n\"\"\"# 4 Preparing Data for Training\n\n## 4.1 Train-Validation Split\n\"\"\"\n\n\"\"\"## 4.2 Formatting Data for `detectron2`\"\"\"\n\ndef convert_coco_to_detectron2_format(\n    imgdir: Path,\n    metadata_df: pd.DataFrame,\n    annot_df: Optional[pd.DataFrame] = None,\n    target_indices: Optional[np.ndarray] = None,\n):\n\n    dataset_dicts = []\n    for _, train_meta_row in metadata_df.iterrows():\n    # Your code for each row goes here\n\n        # Iterate over each image\n        image_id, filename, width, height = train_meta_row.values\n\n        annotations = []\n\n        # If train/validation data, then there will be annotations\n        if annot_df is not None:\n            for _, ann in annot_df.query(\"image_id == @image_id\").iterrows():\n                # Get annotations of current iteration's image\n                class_id = ann[\"category_id\"]\n                gt_masks = ann[\"gt_masks\"]\n                bbox_resized = [\n                    float(ann[\"x_min\"]),\n                    float(ann[\"y_min\"]),\n                    float(ann[\"x_max\"]),\n                    float(ann[\"y_max\"]),\n                ]\n\n                annotation = {\n                    \"bbox\": bbox_resized,\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"segmentation\": gt_masks,\n                    \"category_id\": class_id,\n                }\n\n                annotations.append(annotation)\n\n        # coco format -> detectron2 format dict\n        record = {\n            \"file_name\": str(imgdir/filename),\n            \"image_id\": image_id,\n            \"width\": width,\n            \"height\": height,\n            \"annotations\": annotations\n        }\n\n        dataset_dicts.append(record)\n\n    if target_indices is not None:\n        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n\n    return dataset_dicts\n\n# Create empty lists to store images with tables and images without tables\nimages_with_tables = []\nimages_without_tables = []\n\n# Loop through each row in the DataFrame\nfor _, row in train_df_with_annotations_grouped.iterrows():\n    # Check if category_id for \"table\" (3) is present in the list\n    if 3 in row['category_id']:\n        images_with_tables.append(row['image_id'])\n    else:\n        images_without_tables.append(row['image_id'])\n\n# Create DataFrames for images with tables and images without tables\nimages_with_tables_df = train_metadata[train_metadata['image_id'].isin(images_with_tables)]\nimages_without_tables_df = train_metadata[train_metadata['image_id'].isin(images_without_tables)]\n\n# Convert the DataFrames to detectron2 format:\ndataset_dicts_with_tables = convert_coco_to_detectron2_format(TRAIN_IMG_DIR, images_with_tables_df, train_annot_df)\ndataset_dicts_without_tables = convert_coco_to_detectron2_format(TRAIN_IMG_DIR, images_without_tables_df, train_annot_df)\n\n# Now, you have two separate datasets: dataset_dicts_with_tables containing images with tables annotated,\n# and dataset_dicts_without_tables containing images without tables annotated.\n\n\n# Create DataFrames for images with tables and images without tables\nimages_with_tables_df = train_metadata[train_metadata['image_id'].isin(images_with_tables)]\nimages_without_tables_df = train_metadata[train_metadata['image_id'].isin(images_without_tables)]\n\n\n# Calculate the number of images with tables and without tables\nnum_images_with_tables = len(dataset_dicts_with_tables)\nnum_images_without_tables = len(dataset_dicts_without_tables)\n\nfrom sklearn.model_selection import train_test_split\nimport random\n# Perform a stratified split on the dataset with tables\ndataset_with_tables_train, dataset_with_tables_valid = train_test_split(dataset_dicts_with_tables, test_size=0.2,)\n\n# Perform a stratified split on the dataset without tables\ndataset_without_tables_train, dataset_without_tables_valid = train_test_split(dataset_dicts_without_tables, test_size=0.2)\n\n# Concatenate the datasets to create the final balanced training and validation sets\nbalanced_dataset_train = dataset_with_tables_train + dataset_without_tables_train\nbalanced_dataset_valid = dataset_with_tables_valid + dataset_without_tables_valid\n\n# Shuffle the datasets to further randomize the order of images\nrandom.shuffle(balanced_dataset_train)\nrandom.shuffle(balanced_dataset_valid)\n\ndef check_category_statistics(dataset):\n    category_counts = {}\n    for data in dataset:\n        annotations = data[\"annotations\"]\n        for annotation in annotations:\n            category_id = annotation[\"category_id\"]\n            if category_id not in category_counts:\n                category_counts[category_id] = 0\n            category_counts[category_id] += 1\n\n    category_statistics = {\n        \"category_id\": [],\n        \"category_name\": [],\n        \"num_instances\": []\n    }\n    for category_id, num_instances in category_counts.items():\n        category_statistics[\"category_id\"].append(category_id)\n        category_statistics[\"category_name\"].append(thing_classes[category_id])\n        category_statistics[\"num_instances\"].append(num_instances)\n\n    category_statistics_df = pd.DataFrame(category_statistics)\n    return category_statistics_df\n\ntrain_category_statistics = check_category_statistics(balanced_dataset_train)\nvalid_category_statistics = check_category_statistics(balanced_dataset_valid)\n\nprint(\"Training Set Category Statistics:\")\nprint(train_category_statistics)\n\nprint(\"\\nValidation Set Category Statistics:\")\nprint(valid_category_statistics)\n\n\n\n\"\"\"## 4.3 Registering and Loading Data for `detectron2`\"\"\"\n\nDATA_REGISTER_TRAINING = \"badlad_train\"\nDATA_REGISTER_VALID    = \"badlad_valid\"\nDATA_REGISTER_TEST     = \"badlad_test\"\n\n# Register Training data\nif is_train:\n    DatasetCatalog.register(DATA_REGISTER_TRAINING, lambda: balanced_dataset_train)\n    MetadataCatalog.get(DATA_REGISTER_TRAINING).set(thing_classes=thing_classes)\n    metadata_dicts_train = MetadataCatalog.get(DATA_REGISTER_TRAINING)\n    print(\"dicts training size=\", len(balanced_dataset_train))\n    print(\"################\")\n\n# Register Validation data\nif is_train or is_evaluate:\n    DatasetCatalog.register(DATA_REGISTER_VALID, lambda: balanced_dataset_valid)\n    MetadataCatalog.get(DATA_REGISTER_VALID).set(thing_classes=thing_classes)\n    metadata_dicts_valid = MetadataCatalog.get(DATA_REGISTER_VALID)\n    print(\"dicts valid size=\", len(balanced_dataset_valid))\n    print(\"################\")\n\n# Register Test Inference data\nDatasetCatalog.register(\n    DATA_REGISTER_TEST,\n    lambda: convert_coco_to_detectron2_format(\n        TEST_IMG_DIR,\n        test_metadata,\n    )\n)\n\n# Set Test data categories\nMetadataCatalog.get(DATA_REGISTER_TEST).set(\n    thing_classes=thing_classes_test\n)\n\n# dataset_dicts_test = DatasetCatalog.get(DATA_REGISTER_TEST)\nmetadata_dicts_test = MetadataCatalog.get(DATA_REGISTER_TEST)","metadata":{"_uuid":"f1c29743-3dbb-4086-9664-7bdc36a14224","_cell_guid":"2d79b40f-d254-4dbc-98f2-e24c28c4ba2d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-05T04:42:33.253387Z","iopub.execute_input":"2023-08-05T04:42:33.255181Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"#### LABELS AND METADATA LOADED ####\n['paragraph', 'text_box', 'image', 'table']\n['paragraph', 'text_box', 'image', 'table']\ntrain_metadata size= 20365\ntrain_annot_df size= 425101\n['paragraph', 'text_box', 'image', 'table']\n","output_type":"stream"}]},{"cell_type":"code","source":"! git clone https://github.com/microsoft/unilm.git --depth=1 --quiet\n! sed -i 's/from collections import Iterable/from collections.abc import Iterable/' unilm/dit/object_detection/ditod/table_evaluation/data_structure.py","metadata":{"_uuid":"b111c58d-72dc-4932-8f85-6848341254c5","_cell_guid":"7f637b22-10b8-4d5c-b51e-cc0ea7b06621","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"unilm\")\n\nimport cv2\n\nfrom unilm.dit.object_detection.ditod import add_vit_config","metadata":{"_uuid":"bdc45fd2-503a-4bb4-8c8e-87ba7b81aa13","_cell_guid":"52328355-7058-4fec-a398-7cafbb897692","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile cascade_dit_base.yaml\n_BASE_: \"/kaggle/input/dit-publay-finetuned/Base-RCNN-FPN.yaml\"\nMODEL:\n  PIXEL_MEAN: [ 127.5, 127.5, 127.5 ]\n  PIXEL_STD: [ 127.5, 127.5, 127.5 ]\n  WEIGHTS: \"https://layoutlm.blob.core.windows.net/dit/dit-pts/dit-base-224-p16-500k-62d53a.pth\"\n  VIT:\n    NAME: \"dit_base_patch16\"\n  ROI_HEADS:\n    NAME: CascadeROIHeads\n  ROI_BOX_HEAD:\n    CLS_AGNOSTIC_BBOX_REG: True\n  RPN:\n    POST_NMS_TOPK_TRAIN: 2000\nSOLVER:\n  WARMUP_ITERS: 1000\n  IMS_PER_BATCH: 16\n  MAX_ITER: 60000\n  CHECKPOINT_PERIOD: 2000\nTEST:\n  EVAL_PERIOD: 2000","metadata":{"_uuid":"21e5341e-55de-49bf-8f54-ec19172e81cd","_cell_guid":"e40f2db6-7aff-4f3b-9734-7b5fd4c44dfc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the categories we are going to detect.","metadata":{"_uuid":"7f1274c0-c7f5-4ee7-b712-8e8d250cca85","_cell_guid":"21557b74-8daa-4bb2-b511-67d803c03fe5","trusted":true}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"_uuid":"fd6231c7-6dce-4e7d-bb5f-ac774dadcd91","_cell_guid":"1ebe0fcd-cc5b-4a15-ab59-d335eb4e42d9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n          '/kaggle/input/dit-publay-finetuned/dit-pub-25000.pth', \n          '/kaggle/input/dit-publay-finetuned/dit-pub-30000.pth',\n          '/kaggle/input/dit-publay-finetuned/dit-pub-35000.pth',\n          '/kaggle/input/dit-publay-finetuned/dit-pub-40000.pth',\n          '/kaggle/input/dit-publay-finetuned/dit-pub-45000.pth',\n          '/kaggle/input/dit-publay-finetuned/dit-pub-50000.pth'\n         ]","metadata":{"_uuid":"dde3f584-2795-4511-9cbb-214ad08be658","_cell_guid":"8e5a2ee5-5ca0-4ff9-8507-ad0ec409d091","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rebuild_model(inf_cfg):\n    model = build_model(inf_cfg)\n    _ = DetectionCheckpointer(model).load(inf_cfg.MODEL.WEIGHTS)\n    return model","metadata":{"_uuid":"5a09f285-4adf-498b-9945-529a7e8c6da1","_cell_guid":"e1fc332e-c6fe-4716-a1ae-61250cfd7929","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inf_cfg = get_cfg()\nadd_vit_config(inf_cfg)\ninf_cfg.merge_from_file(\"/kaggle/working/cascade_dit_base.yaml\")\ninf_cfg.SOLVER.IMS_PER_BATCH = 64\ninf_cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\ninf_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\ninf_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\ninf_cfg.MODEL.DEVICE = \"cuda\"\ninf_cfg.DATALOADER.NUM_WORKERS = 2  # lower this if CUDA overflow occurs\ninf_cfg.MODEL.WEIGHTS = str(models[5])\ninf_cfg.OUTPUT_DIR = str(OUTPUT_DIR)\nprint(\"creating cfg.OUTPUT_DIR -> \", inf_cfg.OUTPUT_DIR)\nOUTPUT_DIR.mkdir(exist_ok=True)\nmodel = rebuild_model(inf_cfg)\nmodel.eval()","metadata":{"_uuid":"8a1059f4-3f69-41c5-9b74-c3bef87fc7c1","_cell_guid":"e3f7e1eb-cd75-4deb-ba78-69081ec03cf9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluator = COCOEvaluator(\n    DATA_REGISTER_VALID, inf_cfg, False, output_dir=inf_cfg.OUTPUT_DIR, use_fast_impl=True\n)\n\nval_loader = build_detection_test_loader(inf_cfg, DATA_REGISTER_VALID)\n\nresults = inference_on_dataset(\n    model, val_loader, evaluator=evaluator\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}